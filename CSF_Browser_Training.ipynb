{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDnTepH_414H"
      },
      "source": [
        "# üß† CSF Browser Training Notebook\n",
        "\n",
        "**Contrastive Semantic Features (CSF) Extractor for Sign Language Generation**\n",
        "\n",
        "## Key points\n",
        "- **35 Condition Types** (expanded from 4): Weather, Time, Health, Schedule, Mood, Social, Activity, Financial\n",
        "- **18,885 Training Samples** (up from 6,293)\n",
        "- **4 Languages**: English, Vietnamese, Japanese, French\n",
        "- **Custom 8K BPE Tokenizer** for browser deployment\n",
        "- **~23 MB Model** for real-time inference\n",
        "\n",
        "---\n",
        "\n",
        "## Architecture\n",
        "- **Encoder**: 4-layer Transformer (256 hidden, 4 heads)\n",
        "- **Tokenizer**: Custom BPE (8,000 vocab)\n",
        "- **Output**: 9 classification heads (event, intent, time, condition, agent, object, location, purpose, modifier)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPuyNIHI414I"
      },
      "source": [
        "## 1Ô∏è‚É£ Setup & Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ee9bGYjT414I",
        "outputId": "f5463bcf-f12a-4b6b-ecda-8745a743dce9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m130.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m128.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hMounted at /content/drive\n",
            "‚úÖ Setup complete!\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install -q torch transformers tokenizers onnx onnxruntime scikit-learn tqdm gdown\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "print(\"‚úÖ Setup complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6eiL4X9414J"
      },
      "source": [
        "## 2Ô∏è‚É£ Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCYZ2gAd414J",
        "outputId": "6e73b898-78d8-4309-b04e-0c18c0a9ed0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üì• Downloading dataset from Google Drive...\n",
            "/usr/local/lib/python3.12/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1OWILS9T9kybftmSmI1sopoy9P2oglIgc\n",
            "To: /content/csf_train_19k.jsonl\n",
            "100% 4.43M/4.43M [00:00<00:00, 18.7MB/s]\n",
            "‚úÖ Downloaded to /content/csf_train_19k.jsonl\n",
            "\n",
            "üñ•Ô∏è  Device: cuda\n",
            "   GPU: NVIDIA A100-SXM4-40GB\n",
            "\n",
            "üìä Labels Summary:\n",
            "   event       : 7 classes\n",
            "   intent      : 4 classes\n",
            "   time        : 5 classes\n",
            "   condition   : 35 classes\n",
            "   agent       : 5 classes\n",
            "   object      : 5 classes\n",
            "   location    : 6 classes\n",
            "   purpose     : 2 classes\n",
            "   modifier    : 4 classes\n",
            "\n",
            "   Total output classes: 73\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ============================================================\n",
        "# CONFIGURATION\n",
        "# ============================================================\n",
        "\n",
        "# Paths\n",
        "# Paths - Auto-download from Google Drive\n",
        "DATA_PATH = \"/content/csf_train_19k.jsonl\"\n",
        "GDRIVE_FILE_ID = \"1OWILS9T9kybftmSmI1sopoy9P2oglIgc\"\n",
        "\n",
        "# Auto-download if not exists\n",
        "if not os.path.exists(DATA_PATH):\n",
        "    print(\"üì• Downloading dataset from Google Drive...\")\n",
        "    !gdown --id {GDRIVE_FILE_ID} -O {DATA_PATH}\n",
        "    print(f\"‚úÖ Downloaded to {DATA_PATH}\")\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/csf_browser_v4\"\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# Model hyperparameters\n",
        "CONFIG = {\n",
        "    \"vocab_size\": 8000,\n",
        "    \"hidden_size\": 256,\n",
        "    \"num_attention_heads\": 4,\n",
        "    \"num_hidden_layers\": 4,\n",
        "    \"intermediate_size\": 1024,\n",
        "    \"max_position_embeddings\": 128,\n",
        "    \"dropout\": 0.1,\n",
        "    \"max_length\": 64,\n",
        "}\n",
        "\n",
        "# Training hyperparameters\n",
        "TRAIN_CONFIG = {\n",
        "    \"batch_size\": 64,\n",
        "    \"learning_rate\": 2e-4,\n",
        "    \"epochs\": 15,\n",
        "    \"warmup_ratio\": 0.1,\n",
        "    \"weight_decay\": 0.01,\n",
        "    \"seed\": 42,\n",
        "}\n",
        "\n",
        "# ============================================================\n",
        "# LABELS - 35 CONDITIONS!\n",
        "# ============================================================\n",
        "\n",
        "LABELS = {\n",
        "    \"event\": [\"GO\", \"STAY\", \"BUY\", \"WORK\", \"MEET\", \"EAT\", \"LEARN\"],  # 7\n",
        "    \"intent\": [\"NONE\", \"PLAN\", \"WANT\", \"DECIDE\"],  # 4\n",
        "    \"time\": [\"NONE\", \"TODAY\", \"TOMORROW\", \"YESTERDAY\", \"NOW\"],  # 5\n",
        "    \"condition\": [\n",
        "        \"NONE\",\n",
        "        # Weather (5)\n",
        "        \"IF_RAIN\", \"IF_SUNNY\", \"IF_COLD\", \"IF_HOT\", \"IF_WINDY\",\n",
        "        # Time (5)\n",
        "        \"IF_LATE\", \"IF_EARLY\", \"IF_WEEKEND\", \"IF_NIGHT\", \"IF_MORNING\",\n",
        "        # Health (5)\n",
        "        \"IF_SICK\", \"IF_TIRED\", \"IF_HUNGRY\", \"IF_THIRSTY\", \"IF_FULL\",\n",
        "        # Schedule (4)\n",
        "        \"IF_BUSY\", \"IF_FREE\", \"IF_HOLIDAY\", \"IF_WORKING\",\n",
        "        # Mood (5)\n",
        "        \"IF_BORED\", \"IF_HAPPY\", \"IF_SAD\", \"IF_STRESSED\", \"IF_ANGRY\",\n",
        "        # Social (3)\n",
        "        \"IF_ALONE\", \"IF_WITH_FRIENDS\", \"IF_WITH_FAMILY\",\n",
        "        # Activity (5)\n",
        "        \"IF_FINISH_WORK\", \"IF_FINISH_SCHOOL\", \"IF_FINISH_EATING\", \"IF_WATCH_MOVIE\", \"IF_LISTEN_MUSIC\",\n",
        "        # Financial (2)\n",
        "        \"IF_HAVE_MONEY\", \"IF_NO_MONEY\",\n",
        "    ],  # 35 total\n",
        "    \"agent\": [\"ME\", \"YOU\", \"HE\", \"SHE\", \"THEY\"],  # 5\n",
        "    \"object\": [\"NONE\", \"FOOD\", \"BOOK\", \"MEDICINE\", \"THING\"],  # 5\n",
        "    \"location\": [\"NONE\", \"HOME\", \"SCHOOL\", \"HOSPITAL\", \"OFFICE\", \"STORE\"],  # 6\n",
        "    \"purpose\": [\"NONE\", \"REST\"],  # 2\n",
        "    \"modifier\": [\"NONE\", \"FAST\", \"SLOW\", \"ALONE\"]  # 4\n",
        "}\n",
        "\n",
        "SLOT_NAMES = list(LABELS.keys())\n",
        "NUM_CLASSES = {slot: len(labels) for slot, labels in LABELS.items()}\n",
        "LABEL_TO_ID = {slot: {label: i for i, label in enumerate(labels)} for slot, labels in LABELS.items()}\n",
        "ID_TO_LABEL = {slot: {i: label for i, label in enumerate(labels)} for slot, labels in LABELS.items()}\n",
        "\n",
        "# Set seeds\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(TRAIN_CONFIG[\"seed\"])\n",
        "\n",
        "# Device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"\\nüñ•Ô∏è  Device: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
        "\n",
        "print(f\"\\nüìä Labels Summary:\")\n",
        "for slot, labels in LABELS.items():\n",
        "    print(f\"   {slot:12s}: {len(labels)} classes\")\n",
        "print(f\"\\n   Total output classes: {sum(NUM_CLASSES.values())}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAdrM8ay414J"
      },
      "source": [
        "## 3Ô∏è‚É£ Load & Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMkyNN38414K",
        "outputId": "a643657f-cd33-447d-8e61-9e79fb4b37ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìÇ Loading data...\n",
            "‚úÖ Loaded 18885 samples\n",
            "\n",
            "üìù Sample entry:\n",
            "   Text: C√¥ ·∫•y g·∫∑p vƒÉn ph√≤ng.\n",
            "   CSF:  {'event': 'MEET', 'intent': 'NONE', 'time': 'NONE', 'condition': 'NONE', 'agent': 'SHE', 'object': 'NONE', 'location': 'OFFICE', 'purpose': 'NONE', 'modifier': 'NONE'}\n",
            "\n",
            "üìä Condition distribution (top 10):\n",
            "   NONE                :  4260 (22.6%)\n",
            "   IF_RAIN             :   995 (5.3%)\n",
            "   IF_SICK             :   699 (3.7%)\n",
            "   IF_BUSY             :   658 (3.5%)\n",
            "   IF_SUNNY            :   576 (3.1%)\n",
            "   IF_WEEKEND          :   573 (3.0%)\n",
            "   IF_FREE             :   528 (2.8%)\n",
            "   IF_NIGHT            :   495 (2.6%)\n",
            "   IF_TIRED            :   495 (2.6%)\n",
            "   IF_HUNGRY           :   483 (2.6%)\n",
            "\n",
            "üìä Event distribution:\n",
            "   STAY      :  8223 (43.5%)\n",
            "   GO        :  3409 (18.1%)\n",
            "   EAT       :  3165 (16.8%)\n",
            "   MEET      :  1231 (6.5%)\n",
            "   WORK      :  1197 (6.3%)\n",
            "   BUY       :  1187 (6.3%)\n",
            "   LEARN     :   473 (2.5%)\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# LOAD DATA\n",
        "# ============================================================\n",
        "\n",
        "print(\"üìÇ Loading data...\")\n",
        "\n",
        "# Auto-download from Google Drive if not exists\n",
        "if not os.path.exists(DATA_PATH):\n",
        "    print(\"üì• Downloading dataset from Google Drive...\")\n",
        "    import gdown\n",
        "    gdown.download(id=GDRIVE_FILE_ID, output=DATA_PATH, quiet=False)\n",
        "\n",
        "with open(DATA_PATH, 'r', encoding='utf-8') as f:\n",
        "    data = [json.loads(line) for line in f]\n",
        "\n",
        "print(f\"‚úÖ Loaded {len(data)} samples\")\n",
        "\n",
        "# Show sample\n",
        "print(f\"\\nüìù Sample entry:\")\n",
        "print(f\"   Text: {data[0]['text']}\")\n",
        "print(f\"   CSF:  {data[0]['csf']}\")\n",
        "\n",
        "# Statistics\n",
        "from collections import Counter\n",
        "conditions = Counter(s[\"csf\"][\"condition\"] for s in data)\n",
        "events = Counter(s[\"csf\"][\"event\"] for s in data)\n",
        "\n",
        "print(f\"\\nüìä Condition distribution (top 10):\")\n",
        "for cond, count in conditions.most_common(10):\n",
        "    print(f\"   {cond:20s}: {count:5d} ({100*count/len(data):.1f}%)\")\n",
        "\n",
        "print(f\"\\nüìä Event distribution:\")\n",
        "for event, count in events.most_common():\n",
        "    print(f\"   {event:10s}: {count:5d} ({100*count/len(data):.1f}%)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzMwH2hn414K"
      },
      "source": [
        "## 4Ô∏è‚É£ Train Custom BPE Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hS1tJedW414K",
        "outputId": "658d9fa6-d377-492a-d56d-7cf939fdd291"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üî§ Training custom BPE tokenizer...\n",
            "\n",
            "‚úÖ Tokenizer trained!\n",
            "   Vocab size: 3954\n",
            "   Saved to: /content/drive/MyDrive/csf_browser_v4/tokenizer.json\n",
            "\n",
            "üìù Tokenization examples:\n",
            "   I go to school tomorrow.            ‚Üí 64 tokens\n",
            "   N·∫øu m∆∞a th√¨ t√¥i ·ªü nh√†.              ‚Üí 64 tokens\n",
            "   ÊòéÊó•„ÄÅÂ≠¶Ê†°„Å´Ë°å„Åè„ÄÇ                           ‚Üí 64 tokens\n",
            "   Je travaille √† l'h√¥pital.           ‚Üí 64 tokens\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# TRAIN CUSTOM BPE TOKENIZER\n",
        "# ============================================================\n",
        "\n",
        "from tokenizers import Tokenizer, models, trainers, pre_tokenizers, processors, decoders\n",
        "\n",
        "print(\"üî§ Training custom BPE tokenizer...\")\n",
        "\n",
        "# Extract all texts\n",
        "texts = [s[\"text\"] for s in data]\n",
        "\n",
        "# Save texts temporarily for training\n",
        "with open(\"/content/train_texts.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    for text in texts:\n",
        "        f.write(text + \"\\n\")\n",
        "\n",
        "# Create BPE tokenizer\n",
        "tokenizer = Tokenizer(models.BPE(unk_token=\"[UNK]\"))\n",
        "\n",
        "# Pre-tokenizer: split on whitespace and punctuation\n",
        "tokenizer.pre_tokenizer = pre_tokenizers.ByteLevel(add_prefix_space=True)\n",
        "\n",
        "# Trainer\n",
        "trainer = trainers.BpeTrainer(\n",
        "    vocab_size=CONFIG[\"vocab_size\"],\n",
        "    special_tokens=[\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"],\n",
        "    min_frequency=2,\n",
        "    show_progress=True,\n",
        ")\n",
        "\n",
        "# Train\n",
        "tokenizer.train(files=[\"/content/train_texts.txt\"], trainer=trainer)\n",
        "\n",
        "# Post-processor: add [CLS] and [SEP]\n",
        "tokenizer.post_processor = processors.TemplateProcessing(\n",
        "    single=\"[CLS] $A [SEP]\",\n",
        "    pair=\"[CLS] $A [SEP] $B [SEP]\",\n",
        "    special_tokens=[\n",
        "        (\"[CLS]\", tokenizer.token_to_id(\"[CLS]\")),\n",
        "        (\"[SEP]\", tokenizer.token_to_id(\"[SEP]\")),\n",
        "    ],\n",
        ")\n",
        "\n",
        "# Decoder\n",
        "tokenizer.decoder = decoders.ByteLevel()\n",
        "\n",
        "# Enable padding\n",
        "tokenizer.enable_padding(pad_id=tokenizer.token_to_id(\"[PAD]\"), pad_token=\"[PAD]\", length=CONFIG[\"max_length\"])\n",
        "tokenizer.enable_truncation(max_length=CONFIG[\"max_length\"])\n",
        "\n",
        "# Save tokenizer\n",
        "TOKENIZER_PATH = f\"{OUTPUT_DIR}/tokenizer.json\"\n",
        "tokenizer.save(TOKENIZER_PATH)\n",
        "\n",
        "print(f\"\\n‚úÖ Tokenizer trained!\")\n",
        "print(f\"   Vocab size: {tokenizer.get_vocab_size()}\")\n",
        "print(f\"   Saved to: {TOKENIZER_PATH}\")\n",
        "\n",
        "# Test tokenizer\n",
        "test_texts = [\n",
        "    \"I go to school tomorrow.\",\n",
        "    \"N·∫øu m∆∞a th√¨ t√¥i ·ªü nh√†.\",\n",
        "    \"ÊòéÊó•„ÄÅÂ≠¶Ê†°„Å´Ë°å„Åè„ÄÇ\",\n",
        "    \"Je travaille √† l'h√¥pital.\",\n",
        "]\n",
        "\n",
        "print(f\"\\nüìù Tokenization examples:\")\n",
        "for text in test_texts:\n",
        "    enc = tokenizer.encode(text)\n",
        "    print(f\"   {text[:35]:35s} ‚Üí {len(enc.ids)} tokens\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0sIOqS7414L"
      },
      "source": [
        "## 5Ô∏è‚É£ Dataset & DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZtFx6zu414L",
        "outputId": "66860336-1080-43de-a10e-3d7828aafd91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä Data split:\n",
            "   Train: 16996 samples\n",
            "   Val:   1889 samples\n",
            "\n",
            "‚úÖ DataLoaders created!\n",
            "   Train batches: 266\n",
            "   Val batches: 30\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# DATASET CLASS\n",
        "# ============================================================\n",
        "\n",
        "class CSFDataset(Dataset):\n",
        "    def __init__(self, samples, tokenizer, label_to_id, max_length=64):\n",
        "        self.samples = samples\n",
        "        self.tokenizer = tokenizer\n",
        "        self.label_to_id = label_to_id\n",
        "        self.max_length = max_length\n",
        "        self.slot_names = list(label_to_id.keys())\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample = self.samples[idx]\n",
        "        text = sample[\"text\"]\n",
        "        csf = sample[\"csf\"]\n",
        "\n",
        "        # Tokenize\n",
        "        enc = self.tokenizer.encode(text)\n",
        "        input_ids = enc.ids[:self.max_length]\n",
        "        attention_mask = enc.attention_mask[:self.max_length]\n",
        "\n",
        "        # Pad if needed\n",
        "        pad_len = self.max_length - len(input_ids)\n",
        "        if pad_len > 0:\n",
        "            input_ids = input_ids + [0] * pad_len\n",
        "            attention_mask = attention_mask + [0] * pad_len\n",
        "\n",
        "        # Labels\n",
        "        labels = {}\n",
        "        for slot in self.slot_names:\n",
        "            val = csf.get(slot, \"NONE\")\n",
        "            if val is None:\n",
        "                val = \"NONE\"\n",
        "            # Handle unknown labels\n",
        "            if val not in self.label_to_id[slot]:\n",
        "                val = list(self.label_to_id[slot].keys())[0]  # Default to first\n",
        "            labels[slot] = self.label_to_id[slot][val]\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": torch.tensor(input_ids, dtype=torch.long),\n",
        "            \"attention_mask\": torch.tensor(attention_mask, dtype=torch.long),\n",
        "            \"labels\": {slot: torch.tensor(label, dtype=torch.long) for slot, label in labels.items()}\n",
        "        }\n",
        "\n",
        "# ============================================================\n",
        "# CREATE DATALOADERS\n",
        "# ============================================================\n",
        "\n",
        "# Split data\n",
        "train_data, val_data = train_test_split(data, test_size=0.1, random_state=TRAIN_CONFIG[\"seed\"])\n",
        "\n",
        "print(f\"üìä Data split:\")\n",
        "print(f\"   Train: {len(train_data)} samples\")\n",
        "print(f\"   Val:   {len(val_data)} samples\")\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = CSFDataset(train_data, tokenizer, LABEL_TO_ID, CONFIG[\"max_length\"])\n",
        "val_dataset = CSFDataset(val_data, tokenizer, LABEL_TO_ID, CONFIG[\"max_length\"])\n",
        "\n",
        "# Create dataloaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=TRAIN_CONFIG[\"batch_size\"], shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=TRAIN_CONFIG[\"batch_size\"], shuffle=False, num_workers=2)\n",
        "\n",
        "print(f\"\\n‚úÖ DataLoaders created!\")\n",
        "print(f\"   Train batches: {len(train_loader)}\")\n",
        "print(f\"   Val batches: {len(val_loader)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGmyLgfu414L"
      },
      "source": [
        "## 6Ô∏è‚É£ Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqOqo5Iw414L",
        "outputId": "9b8cd946-1d9d-454f-fb1b-b79f35a38154"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üß† Model created!\n",
            "   Total parameters:     5,851,209\n",
            "   Trainable parameters: 5,851,209\n",
            "   Estimated size:       22.3 MB\n",
            "\n",
            "üìê Architecture:\n",
            "   Vocab size: 8000\n",
            "   Hidden size: 256\n",
            "   Layers: 4\n",
            "   Attention heads: 4\n",
            "   FFN size: 1024\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# MODEL ARCHITECTURE\n",
        "# ============================================================\n",
        "\n",
        "class CSFClassificationHead(nn.Module):\n",
        "    \"\"\"Classification head for each slot.\"\"\"\n",
        "    def __init__(self, hidden_size, num_classes, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.dense = nn.Linear(hidden_size, hidden_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.classifier = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.dropout(x)\n",
        "        x = torch.tanh(self.dense(x))\n",
        "        x = self.dropout(x)\n",
        "        return self.classifier(x)\n",
        "\n",
        "\n",
        "class CSFExtractor(nn.Module):\n",
        "    \"\"\"CSF Extractor with Transformer encoder.\"\"\"\n",
        "    def __init__(self, config, num_classes):\n",
        "        super().__init__()\n",
        "        self.hidden_size = config[\"hidden_size\"]\n",
        "\n",
        "        # Embeddings\n",
        "        self.word_embeddings = nn.Embedding(\n",
        "            config[\"vocab_size\"],\n",
        "            config[\"hidden_size\"],\n",
        "            padding_idx=0\n",
        "        )\n",
        "        self.position_embeddings = nn.Embedding(\n",
        "            config[\"max_position_embeddings\"],\n",
        "            config[\"hidden_size\"]\n",
        "        )\n",
        "        self.layer_norm = nn.LayerNorm(config[\"hidden_size\"], eps=1e-6)\n",
        "        self.dropout = nn.Dropout(config[\"dropout\"])\n",
        "\n",
        "        # Transformer encoder\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=config[\"hidden_size\"],\n",
        "            nhead=config[\"num_attention_heads\"],\n",
        "            dim_feedforward=config[\"intermediate_size\"],\n",
        "            dropout=config[\"dropout\"],\n",
        "            activation=\"gelu\",\n",
        "            batch_first=True,\n",
        "            norm_first=True\n",
        "        )\n",
        "        self.encoder = nn.TransformerEncoder(\n",
        "            encoder_layer,\n",
        "            num_layers=config[\"num_hidden_layers\"]\n",
        "        )\n",
        "\n",
        "        # Classification heads\n",
        "        self.classification_heads = nn.ModuleDict({\n",
        "            slot: CSFClassificationHead(\n",
        "                config[\"hidden_size\"],\n",
        "                num_classes[slot],\n",
        "                config[\"dropout\"]\n",
        "            ) for slot in num_classes.keys()\n",
        "        })\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None):\n",
        "        batch_size, seq_len = input_ids.shape\n",
        "\n",
        "        # Position IDs\n",
        "        position_ids = torch.arange(seq_len, device=input_ids.device).unsqueeze(0).expand(batch_size, -1)\n",
        "\n",
        "        # Embeddings\n",
        "        embeddings = self.word_embeddings(input_ids) + self.position_embeddings(position_ids)\n",
        "        embeddings = self.dropout(self.layer_norm(embeddings))\n",
        "\n",
        "        # Attention mask for transformer (True = ignore)\n",
        "        mask = (attention_mask == 0) if attention_mask is not None else None\n",
        "\n",
        "        # Encode\n",
        "        encoder_output = self.encoder(embeddings, src_key_padding_mask=mask)\n",
        "\n",
        "        # Use [CLS] token (index 0)\n",
        "        cls_output = encoder_output[:, 0, :]\n",
        "\n",
        "        # Classify each slot\n",
        "        return {slot: head(cls_output) for slot, head in self.classification_heads.items()}\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# CREATE MODEL\n",
        "# ============================================================\n",
        "\n",
        "model = CSFExtractor(CONFIG, NUM_CLASSES).to(device)\n",
        "\n",
        "# Count parameters\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f\"\\nüß† Model created!\")\n",
        "print(f\"   Total parameters:     {total_params:,}\")\n",
        "print(f\"   Trainable parameters: {trainable_params:,}\")\n",
        "print(f\"   Estimated size:       {total_params * 4 / 1024 / 1024:.1f} MB\")\n",
        "\n",
        "# Show architecture\n",
        "print(f\"\\nüìê Architecture:\")\n",
        "print(f\"   Vocab size: {CONFIG['vocab_size']}\")\n",
        "print(f\"   Hidden size: {CONFIG['hidden_size']}\")\n",
        "print(f\"   Layers: {CONFIG['num_hidden_layers']}\")\n",
        "print(f\"   Attention heads: {CONFIG['num_attention_heads']}\")\n",
        "print(f\"   FFN size: {CONFIG['intermediate_size']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nQvaTHm414M"
      },
      "source": [
        "## 7Ô∏è‚É£ Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYw8JR2g414M",
        "outputId": "24d0e6fd-2545-47bf-a08b-397106348cf0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "‚öôÔ∏è  Training setup:\n",
            "   Optimizer: AdamW\n",
            "   Learning rate: 0.0002\n",
            "   Epochs: 15\n",
            "   Total steps: 3990\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# TRAINING SETUP\n",
        "# ============================================================\n",
        "\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import OneCycleLR\n",
        "\n",
        "# Optimizer\n",
        "optimizer = AdamW(\n",
        "    model.parameters(),\n",
        "    lr=TRAIN_CONFIG[\"learning_rate\"],\n",
        "    weight_decay=TRAIN_CONFIG[\"weight_decay\"]\n",
        ")\n",
        "\n",
        "# Scheduler\n",
        "total_steps = len(train_loader) * TRAIN_CONFIG[\"epochs\"]\n",
        "scheduler = OneCycleLR(\n",
        "    optimizer,\n",
        "    max_lr=TRAIN_CONFIG[\"learning_rate\"],\n",
        "    total_steps=total_steps,\n",
        "    pct_start=TRAIN_CONFIG[\"warmup_ratio\"],\n",
        "    anneal_strategy='cos'\n",
        ")\n",
        "\n",
        "# Loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "print(f\"\\n‚öôÔ∏è  Training setup:\")\n",
        "print(f\"   Optimizer: AdamW\")\n",
        "print(f\"   Learning rate: {TRAIN_CONFIG['learning_rate']}\")\n",
        "print(f\"   Epochs: {TRAIN_CONFIG['epochs']}\")\n",
        "print(f\"   Total steps: {total_steps}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UC2zXlpR414M",
        "outputId": "fbc6495a-4854-43d0-e3f9-1ba2a41e97e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "üöÄ STARTING TRAINING\n",
            "============================================================\n",
            "\n",
            "üìÖ Epoch 1/15\n",
            "----------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 266/266 [00:07<00:00, 35.10it/s, loss=6.7018, acc=68.5%]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30/30 [00:00<00:00, 76.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "   Train Loss: 8.9983 | Train Acc: 68.50%\n",
            "   Val Loss:   6.5203 | Val Acc:   77.20%\n",
            "\n",
            "   Slot Accuracies (Val):\n",
            "      event       : 49.1%\n",
            "      intent      : 94.7%\n",
            "      time        : 89.8%\n",
            "      condition   : 29.3%\n",
            "      agent       : 85.8%\n",
            "      object      : 96.6%\n",
            "      location    : 62.7%\n",
            "      purpose     : 91.1%\n",
            "      modifier    : 95.7%\n",
            "\n",
            "   ‚úÖ New best model saved! (77.20%)\n",
            "\n",
            "üìÖ Epoch 2/15\n",
            "----------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 266/266 [00:06<00:00, 41.38it/s, loss=4.4123, acc=80.8%]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30/30 [00:00<00:00, 79.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "   Train Loss: 5.4513 | Train Acc: 80.79%\n",
            "   Val Loss:   3.5924 | Val Acc:   87.87%\n",
            "\n",
            "   Slot Accuracies (Val):\n",
            "      event       : 74.1%\n",
            "      intent      : 95.5%\n",
            "      time        : 98.0%\n",
            "      condition   : 56.9%\n",
            "      agent       : 93.0%\n",
            "      object      : 97.1%\n",
            "      location    : 84.1%\n",
            "      purpose     : 96.5%\n",
            "      modifier    : 95.7%\n",
            "\n",
            "   ‚úÖ New best model saved! (87.87%)\n",
            "\n",
            "üìÖ Epoch 3/15\n",
            "----------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 266/266 [00:06<00:00, 41.28it/s, loss=2.8357, acc=89.2%]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30/30 [00:00<00:00, 86.14it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "   Train Loss: 3.1729 | Train Acc: 89.21%\n",
            "   Val Loss:   1.8658 | Val Acc:   93.84%\n",
            "\n",
            "   Slot Accuracies (Val):\n",
            "      event       : 88.5%\n",
            "      intent      : 96.3%\n",
            "      time        : 99.3%\n",
            "      condition   : 79.0%\n",
            "      agent       : 95.3%\n",
            "      object      : 97.1%\n",
            "      location    : 92.8%\n",
            "      purpose     : 99.3%\n",
            "      modifier    : 97.0%\n",
            "\n",
            "   ‚úÖ New best model saved! (93.84%)\n",
            "\n",
            "üìÖ Epoch 4/15\n",
            "----------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 266/266 [00:06<00:00, 40.79it/s, loss=1.7037, acc=93.5%]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30/30 [00:00<00:00, 78.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "   Train Loss: 1.9497 | Train Acc: 93.46%\n",
            "   Val Loss:   1.2018 | Val Acc:   96.15%\n",
            "\n",
            "   Slot Accuracies (Val):\n",
            "      event       : 93.0%\n",
            "      intent      : 96.8%\n",
            "      time        : 99.3%\n",
            "      condition   : 90.3%\n",
            "      agent       : 96.1%\n",
            "      object      : 97.6%\n",
            "      location    : 95.0%\n",
            "      purpose     : 99.0%\n",
            "      modifier    : 98.3%\n",
            "\n",
            "   ‚úÖ New best model saved! (96.15%)\n",
            "\n",
            "üìÖ Epoch 5/15\n",
            "----------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 266/266 [00:06<00:00, 41.18it/s, loss=1.0120, acc=95.6%]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30/30 [00:00<00:00, 78.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "   Train Loss: 1.3192 | Train Acc: 95.61%\n",
            "   Val Loss:   0.7920 | Val Acc:   97.58%\n",
            "\n",
            "   Slot Accuracies (Val):\n",
            "      event       : 94.8%\n",
            "      intent      : 97.7%\n",
            "      time        : 99.4%\n",
            "      condition   : 95.8%\n",
            "      agent       : 97.1%\n",
            "      object      : 98.6%\n",
            "      location    : 96.2%\n",
            "      purpose     : 99.7%\n",
            "      modifier    : 98.9%\n",
            "\n",
            "   ‚úÖ New best model saved! (97.58%)\n",
            "\n",
            "üìÖ Epoch 6/15\n",
            "----------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 266/266 [00:06<00:00, 40.98it/s, loss=1.0391, acc=96.8%]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30/30 [00:00<00:00, 82.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "   Train Loss: 0.9502 | Train Acc: 96.84%\n",
            "   Val Loss:   0.6250 | Val Acc:   98.08%\n",
            "\n",
            "   Slot Accuracies (Val):\n",
            "      event       : 95.8%\n",
            "      intent      : 98.7%\n",
            "      time        : 99.6%\n",
            "      condition   : 97.9%\n",
            "      agent       : 97.9%\n",
            "      object      : 98.6%\n",
            "      location    : 95.8%\n",
            "      purpose     : 99.6%\n",
            "      modifier    : 98.9%\n",
            "\n",
            "   ‚úÖ New best model saved! (98.08%)\n",
            "\n",
            "üìÖ Epoch 7/15\n",
            "----------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 266/266 [00:06<00:00, 41.98it/s, loss=0.6526, acc=97.7%]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30/30 [00:00<00:00, 73.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "   Train Loss: 0.7135 | Train Acc: 97.66%\n",
            "   Val Loss:   0.4973 | Val Acc:   98.51%\n",
            "\n",
            "   Slot Accuracies (Val):\n",
            "      event       : 96.3%\n",
            "      intent      : 98.7%\n",
            "      time        : 99.5%\n",
            "      condition   : 98.5%\n",
            "      agent       : 98.4%\n",
            "      object      : 99.0%\n",
            "      location    : 97.6%\n",
            "      purpose     : 99.6%\n",
            "      modifier    : 99.0%\n",
            "\n",
            "   ‚úÖ New best model saved! (98.51%)\n",
            "\n",
            "üìÖ Epoch 8/15\n",
            "----------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 266/266 [00:06<00:00, 41.92it/s, loss=0.4298, acc=98.1%]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30/30 [00:00<00:00, 82.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "   Train Loss: 0.5806 | Train Acc: 98.08%\n",
            "   Val Loss:   0.4351 | Val Acc:   98.58%\n",
            "\n",
            "   Slot Accuracies (Val):\n",
            "      event       : 96.6%\n",
            "      intent      : 98.8%\n",
            "      time        : 99.5%\n",
            "      condition   : 98.9%\n",
            "      agent       : 98.4%\n",
            "      object      : 99.0%\n",
            "      location    : 97.4%\n",
            "      purpose     : 99.6%\n",
            "      modifier    : 99.0%\n",
            "\n",
            "   ‚úÖ New best model saved! (98.58%)\n",
            "\n",
            "üìÖ Epoch 9/15\n",
            "----------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 266/266 [00:06<00:00, 42.18it/s, loss=0.4829, acc=98.4%]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30/30 [00:00<00:00, 85.96it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "   Train Loss: 0.4666 | Train Acc: 98.44%\n",
            "   Val Loss:   0.4120 | Val Acc:   98.68%\n",
            "\n",
            "   Slot Accuracies (Val):\n",
            "      event       : 97.2%\n",
            "      intent      : 98.6%\n",
            "      time        : 99.5%\n",
            "      condition   : 99.0%\n",
            "      agent       : 98.5%\n",
            "      object      : 99.3%\n",
            "      location    : 97.2%\n",
            "      purpose     : 99.6%\n",
            "      modifier    : 99.2%\n",
            "\n",
            "   ‚úÖ New best model saved! (98.68%)\n",
            "\n",
            "üìÖ Epoch 10/15\n",
            "----------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 266/266 [00:06<00:00, 41.47it/s, loss=0.1863, acc=98.7%]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30/30 [00:00<00:00, 80.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "   Train Loss: 0.4006 | Train Acc: 98.66%\n",
            "   Val Loss:   0.3716 | Val Acc:   98.87%\n",
            "\n",
            "   Slot Accuracies (Val):\n",
            "      event       : 97.3%\n",
            "      intent      : 99.0%\n",
            "      time        : 99.5%\n",
            "      condition   : 99.2%\n",
            "      agent       : 98.8%\n",
            "      object      : 99.2%\n",
            "      location    : 97.8%\n",
            "      purpose     : 99.7%\n",
            "      modifier    : 99.3%\n",
            "\n",
            "   ‚úÖ New best model saved! (98.87%)\n",
            "\n",
            "üìÖ Epoch 11/15\n",
            "----------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 266/266 [00:06<00:00, 40.45it/s, loss=0.6081, acc=98.9%]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30/30 [00:00<00:00, 79.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "   Train Loss: 0.3344 | Train Acc: 98.90%\n",
            "   Val Loss:   0.3659 | Val Acc:   98.91%\n",
            "\n",
            "   Slot Accuracies (Val):\n",
            "      event       : 97.5%\n",
            "      intent      : 99.2%\n",
            "      time        : 99.6%\n",
            "      condition   : 99.3%\n",
            "      agent       : 98.7%\n",
            "      object      : 99.2%\n",
            "      location    : 97.7%\n",
            "      purpose     : 99.6%\n",
            "      modifier    : 99.3%\n",
            "\n",
            "   ‚úÖ New best model saved! (98.91%)\n",
            "\n",
            "üìÖ Epoch 12/15\n",
            "----------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 266/266 [00:06<00:00, 41.92it/s, loss=0.6581, acc=99.0%]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30/30 [00:00<00:00, 81.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "   Train Loss: 0.3028 | Train Acc: 99.01%\n",
            "   Val Loss:   0.3505 | Val Acc:   98.98%\n",
            "\n",
            "   Slot Accuracies (Val):\n",
            "      event       : 97.6%\n",
            "      intent      : 99.1%\n",
            "      time        : 99.6%\n",
            "      condition   : 99.4%\n",
            "      agent       : 99.0%\n",
            "      object      : 99.3%\n",
            "      location    : 97.9%\n",
            "      purpose     : 99.6%\n",
            "      modifier    : 99.4%\n",
            "\n",
            "   ‚úÖ New best model saved! (98.98%)\n",
            "\n",
            "üìÖ Epoch 13/15\n",
            "----------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 266/266 [00:06<00:00, 40.80it/s, loss=0.2237, acc=99.1%]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30/30 [00:00<00:00, 78.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "   Train Loss: 0.2704 | Train Acc: 99.12%\n",
            "   Val Loss:   0.3472 | Val Acc:   99.03%\n",
            "\n",
            "   Slot Accuracies (Val):\n",
            "      event       : 97.8%\n",
            "      intent      : 99.2%\n",
            "      time        : 99.6%\n",
            "      condition   : 99.4%\n",
            "      agent       : 99.0%\n",
            "      object      : 99.2%\n",
            "      location    : 97.9%\n",
            "      purpose     : 99.7%\n",
            "      modifier    : 99.5%\n",
            "\n",
            "   ‚úÖ New best model saved! (99.03%)\n",
            "\n",
            "üìÖ Epoch 14/15\n",
            "----------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 266/266 [00:06<00:00, 42.57it/s, loss=0.1528, acc=99.2%]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30/30 [00:00<00:00, 77.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "   Train Loss: 0.2565 | Train Acc: 99.16%\n",
            "   Val Loss:   0.3446 | Val Acc:   99.00%\n",
            "\n",
            "   Slot Accuracies (Val):\n",
            "      event       : 97.8%\n",
            "      intent      : 99.2%\n",
            "      time        : 99.6%\n",
            "      condition   : 99.4%\n",
            "      agent       : 99.0%\n",
            "      object      : 99.2%\n",
            "      location    : 97.8%\n",
            "      purpose     : 99.6%\n",
            "      modifier    : 99.4%\n",
            "\n",
            "üìÖ Epoch 15/15\n",
            "----------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 266/266 [00:06<00:00, 41.66it/s, loss=0.1478, acc=99.2%]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30/30 [00:00<00:00, 78.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "   Train Loss: 0.2552 | Train Acc: 99.17%\n",
            "   Val Loss:   0.3434 | Val Acc:   99.01%\n",
            "\n",
            "   Slot Accuracies (Val):\n",
            "      event       : 97.7%\n",
            "      intent      : 99.2%\n",
            "      time        : 99.6%\n",
            "      condition   : 99.3%\n",
            "      agent       : 99.0%\n",
            "      object      : 99.3%\n",
            "      location    : 97.9%\n",
            "      purpose     : 99.6%\n",
            "      modifier    : 99.5%\n",
            "\n",
            "============================================================\n",
            "üèÜ Training complete! Best Val Accuracy: 99.03%\n",
            "============================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# TRAINING LOOP\n",
        "# ============================================================\n",
        "\n",
        "def train_epoch(model, loader, optimizer, scheduler, criterion, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct = {slot: 0 for slot in SLOT_NAMES}\n",
        "    total = 0\n",
        "\n",
        "    pbar = tqdm(loader, desc=\"Training\")\n",
        "    for batch in pbar:\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        labels = {slot: batch[\"labels\"][slot].to(device) for slot in SLOT_NAMES}\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(input_ids, attention_mask)\n",
        "\n",
        "        loss = sum(criterion(outputs[slot], labels[slot]) for slot in SLOT_NAMES)\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        total += input_ids.size(0)\n",
        "\n",
        "        for slot in SLOT_NAMES:\n",
        "            preds = outputs[slot].argmax(dim=-1)\n",
        "            correct[slot] += (preds == labels[slot]).sum().item()\n",
        "\n",
        "        avg_acc = sum(correct[s] for s in SLOT_NAMES) / (total * len(SLOT_NAMES)) * 100\n",
        "        pbar.set_postfix({\"loss\": f\"{loss.item():.4f}\", \"acc\": f\"{avg_acc:.1f}%\"})\n",
        "\n",
        "    avg_loss = total_loss / len(loader)\n",
        "    accuracies = {slot: correct[slot] / total * 100 for slot in SLOT_NAMES}\n",
        "    return avg_loss, accuracies\n",
        "\n",
        "\n",
        "def evaluate(model, loader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    correct = {slot: 0 for slot in SLOT_NAMES}\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(loader, desc=\"Evaluating\"):\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            labels = {slot: batch[\"labels\"][slot].to(device) for slot in SLOT_NAMES}\n",
        "\n",
        "            outputs = model(input_ids, attention_mask)\n",
        "\n",
        "            loss = sum(criterion(outputs[slot], labels[slot]) for slot in SLOT_NAMES)\n",
        "            total_loss += loss.item()\n",
        "            total += input_ids.size(0)\n",
        "\n",
        "            for slot in SLOT_NAMES:\n",
        "                preds = outputs[slot].argmax(dim=-1)\n",
        "                correct[slot] += (preds == labels[slot]).sum().item()\n",
        "\n",
        "    avg_loss = total_loss / len(loader)\n",
        "    accuracies = {slot: correct[slot] / total * 100 for slot in SLOT_NAMES}\n",
        "    return avg_loss, accuracies\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# RUN TRAINING\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"üöÄ STARTING TRAINING\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "best_val_acc = 0\n",
        "history = {\"train_loss\": [], \"val_loss\": [], \"train_acc\": [], \"val_acc\": []}\n",
        "\n",
        "for epoch in range(TRAIN_CONFIG[\"epochs\"]):\n",
        "    print(f\"\\nüìÖ Epoch {epoch + 1}/{TRAIN_CONFIG['epochs']}\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    # Train\n",
        "    train_loss, train_acc = train_epoch(model, train_loader, optimizer, scheduler, criterion, device)\n",
        "\n",
        "    # Evaluate\n",
        "    val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n",
        "\n",
        "    # Calculate average accuracy\n",
        "    avg_train_acc = sum(train_acc.values()) / len(train_acc)\n",
        "    avg_val_acc = sum(val_acc.values()) / len(val_acc)\n",
        "\n",
        "    # Save history\n",
        "    history[\"train_loss\"].append(train_loss)\n",
        "    history[\"val_loss\"].append(val_loss)\n",
        "    history[\"train_acc\"].append(avg_train_acc)\n",
        "    history[\"val_acc\"].append(avg_val_acc)\n",
        "\n",
        "    print(f\"\\n   Train Loss: {train_loss:.4f} | Train Acc: {avg_train_acc:.2f}%\")\n",
        "    print(f\"   Val Loss:   {val_loss:.4f} | Val Acc:   {avg_val_acc:.2f}%\")\n",
        "\n",
        "    # Show per-slot accuracy\n",
        "    print(f\"\\n   Slot Accuracies (Val):\")\n",
        "    for slot in SLOT_NAMES:\n",
        "        print(f\"      {slot:12s}: {val_acc[slot]:.1f}%\")\n",
        "\n",
        "    # Save best model\n",
        "    if avg_val_acc > best_val_acc:\n",
        "        best_val_acc = avg_val_acc\n",
        "        torch.save(model.state_dict(), f\"{OUTPUT_DIR}/best_model.pt\")\n",
        "        print(f\"\\n   ‚úÖ New best model saved! ({best_val_acc:.2f}%)\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(f\"üèÜ Training complete! Best Val Accuracy: {best_val_acc:.2f}%\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_rWxih4414M"
      },
      "source": [
        "## 8Ô∏è‚É£ Save Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8VCEZt39414M",
        "outputId": "004e0bf0-d879-4153-9b93-2866f0ff202d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "‚úÖ Model saved to: /content/drive/MyDrive/csf_browser_v4\n",
            "   - pytorch_model.bin\n",
            "   - config.json\n",
            "   - labels.json\n",
            "   - tokenizer.json\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# SAVE FINAL MODEL\n",
        "# ============================================================\n",
        "\n",
        "# Load best model\n",
        "model.load_state_dict(torch.load(f\"{OUTPUT_DIR}/best_model.pt\"))\n",
        "model.eval()\n",
        "\n",
        "# Save PyTorch model\n",
        "torch.save(model.state_dict(), f\"{OUTPUT_DIR}/pytorch_model.bin\")\n",
        "\n",
        "# Save config\n",
        "config_to_save = {\n",
        "    **CONFIG,\n",
        "    \"num_classes\": NUM_CLASSES,\n",
        "    \"slot_names\": SLOT_NAMES,\n",
        "}\n",
        "with open(f\"{OUTPUT_DIR}/config.json\", \"w\") as f:\n",
        "    json.dump(config_to_save, f, indent=2)\n",
        "\n",
        "# Save labels\n",
        "with open(f\"{OUTPUT_DIR}/labels.json\", \"w\") as f:\n",
        "    json.dump(LABELS, f, indent=2)\n",
        "\n",
        "print(f\"\\n‚úÖ Model saved to: {OUTPUT_DIR}\")\n",
        "print(f\"   - pytorch_model.bin\")\n",
        "print(f\"   - config.json\")\n",
        "print(f\"   - labels.json\")\n",
        "print(f\"   - tokenizer.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7OyADgD414M"
      },
      "source": [
        "## 9Ô∏è‚É£ Export to ONNX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PNb-R9O6a6j",
        "outputId": "29113ddb-092b-4e0a-d979-b9a1910d8221"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting onnxscript\n",
            "  Downloading onnxscript-0.5.7-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: ml_dtypes in /usr/local/lib/python3.12/dist-packages (from onnxscript) (0.5.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from onnxscript) (2.0.2)\n",
            "Collecting onnx_ir<2,>=0.1.12 (from onnxscript)\n",
            "  Downloading onnx_ir-0.1.13-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: onnx>=1.16 in /usr/local/lib/python3.12/dist-packages (from onnxscript) (1.20.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from onnxscript) (25.0)\n",
            "Requirement already satisfied: typing_extensions>=4.10 in /usr/local/lib/python3.12/dist-packages (from onnxscript) (4.15.0)\n",
            "Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.12/dist-packages (from onnx>=1.16->onnxscript) (5.29.5)\n",
            "Downloading onnxscript-0.5.7-py3-none-any.whl (693 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m693.4/693.4 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx_ir-0.1.13-py3-none-any.whl (133 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m133.1/133.1 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: onnx_ir, onnxscript\n",
            "Successfully installed onnx_ir-0.1.13 onnxscript-0.5.7\n"
          ]
        }
      ],
      "source": [
        "!pip install onnxscript"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHrcNNH7414N",
        "outputId": "1e5f5bcf-55cd-4c29-dcc6-13133fa67e72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üì¶ Exporting to ONNX...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-1770467684.py:32: UserWarning: # 'dynamic_axes' is not recommended when dynamo=True, and may lead to 'torch._dynamo.exc.UserError: Constraints violated.' Supply the 'dynamic_shapes' argument instead if export is unsuccessful.\n",
            "  torch.onnx.export(\n",
            "W1230 15:39:08.002000 469 torch/onnx/_internal/exporter/_compat.py:114] Setting ONNX exporter to use operator set version 18 because the requested opset_version 14 is a lower version than we have implementations for. Automatic version conversion will be performed, which may not be successful at converting to the requested version. If version conversion is unsuccessful, the opset version of the exported model will be kept at 18. Please consider setting opset_version >=18 to leverage latest ONNX features\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[torch.onnx] Obtain model graph for `CSFExtractorONNX([...]` with `torch.export.export(..., strict=False)`...\n",
            "[torch.onnx] Obtain model graph for `CSFExtractorONNX([...]` with `torch.export.export(..., strict=False)`... ‚úÖ\n",
            "[torch.onnx] Run decomposition...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:onnxscript.version_converter:The model version conversion is not supported by the onnxscript version converter and fallback is enabled. The model will be converted using the onnx C API (target version: 14).\n",
            "WARNING:onnxscript.version_converter:Failed to convert the model to the target version 14 using the ONNX C API. The model was not modified\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/onnxscript/version_converter/__init__.py\", line 127, in call\n",
            "    converted_proto = _c_api_utils.call_onnx_api(\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/onnxscript/version_converter/_c_api_utils.py\", line 65, in call_onnx_api\n",
            "    result = func(proto)\n",
            "             ^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/onnxscript/version_converter/__init__.py\", line 122, in _partial_convert_version\n",
            "    return onnx.version_converter.convert_version(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/onnx/version_converter.py\", line 39, in convert_version\n",
            "    converted_model_str = C.convert_version(model_str, target_version)\n",
            "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: /github/workspace/onnx/version_converter/adapters/no_previous_version.h:26: adapt: Assertion `false` failed: No Previous Version of LayerNormalization exists\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[torch.onnx] Run decomposition... ‚úÖ\n",
            "[torch.onnx] Translate the graph into ONNX...\n",
            "[torch.onnx] Translate the graph into ONNX... ‚úÖ\n",
            "Applied 13 of general pattern rewrite rules.\n",
            "\n",
            "‚úÖ ONNX model exported!\n",
            "   Path: /content/drive/MyDrive/csf_browser_v4/model.onnx\n",
            "   Size: 0.42 MB\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# EXPORT TO ONNX\n",
        "# ============================================================\n",
        "\n",
        "import onnx\n",
        "\n",
        "print(\"üì¶ Exporting to ONNX...\")\n",
        "\n",
        "# Wrapper for ONNX export (returns tuple instead of dict)\n",
        "class CSFExtractorONNX(nn.Module):\n",
        "    def __init__(self, base_model):\n",
        "        super().__init__()\n",
        "        self.model = base_model\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        logits = self.model(input_ids, attention_mask)\n",
        "        return tuple(logits[slot] for slot in SLOT_NAMES)\n",
        "\n",
        "# Create export model\n",
        "model.eval()\n",
        "export_model = CSFExtractorONNX(model)\n",
        "export_model.eval()\n",
        "\n",
        "# Dummy inputs\n",
        "dummy_input_ids = torch.randint(0, CONFIG[\"vocab_size\"], (1, CONFIG[\"max_length\"])).to(device)\n",
        "dummy_attention_mask = torch.ones(1, CONFIG[\"max_length\"], dtype=torch.long).to(device)\n",
        "\n",
        "# Export\n",
        "ONNX_PATH = f\"{OUTPUT_DIR}/model.onnx\"\n",
        "\n",
        "with torch.no_grad():\n",
        "    torch.onnx.export(\n",
        "        export_model,\n",
        "        (dummy_input_ids, dummy_attention_mask),\n",
        "        ONNX_PATH,\n",
        "        export_params=True,\n",
        "        opset_version=14,\n",
        "        do_constant_folding=True,\n",
        "        input_names=[\"input_ids\", \"attention_mask\"],\n",
        "        output_names=[f\"logits_{slot}\" for slot in SLOT_NAMES],\n",
        "        dynamic_axes={\n",
        "            \"input_ids\": {0: \"batch_size\"},\n",
        "            \"attention_mask\": {0: \"batch_size\"},\n",
        "            **{f\"logits_{slot}\": {0: \"batch_size\"} for slot in SLOT_NAMES}\n",
        "        }\n",
        "    )\n",
        "\n",
        "# Verify\n",
        "onnx_model = onnx.load(ONNX_PATH)\n",
        "onnx.checker.check_model(onnx_model)\n",
        "\n",
        "# Get size\n",
        "onnx_size = os.path.getsize(ONNX_PATH) / 1024 / 1024\n",
        "\n",
        "print(f\"\\n‚úÖ ONNX model exported!\")\n",
        "print(f\"   Path: {ONNX_PATH}\")\n",
        "print(f\"   Size: {onnx_size:.2f} MB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KWI6b2O414N"
      },
      "source": [
        "## üîü Test Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdnR6tJw414N",
        "outputId": "27e8e97f-2695-432e-d326-0915dab820eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üß™ Testing ONNX inference...\n",
            "   Provider: CPUExecutionProvider\n",
            "\n",
            "======================================================================\n",
            "üìù INFERENCE EXAMPLES\n",
            "======================================================================\n",
            "\n",
            "üó£Ô∏è  I go to school tomorrow.\n",
            "ü§ü TOMORROW SCHOOL GO\n",
            "   condition=NONE\n",
            "\n",
            "üó£Ô∏è  She stays at home.\n",
            "ü§ü SHE HOME STAY\n",
            "   condition=NONE\n",
            "\n",
            "üó£Ô∏è  If it rains, I stay home.\n",
            "ü§ü IF_RAIN HOME STAY\n",
            "   condition=IF_RAIN\n",
            "\n",
            "üó£Ô∏è  If it's sunny, I go to the park.\n",
            "ü§ü IF_SUNNY GO\n",
            "   condition=IF_SUNNY\n",
            "\n",
            "üó£Ô∏è  If I'm bored, I watch Netflix.\n",
            "ü§ü IF_BORED HOME STAY\n",
            "   condition=IF_BORED\n",
            "\n",
            "üó£Ô∏è  When I'm tired, I take a nap.\n",
            "ü§ü IF_TIRED HOME STAY REST\n",
            "   condition=IF_TIRED\n",
            "\n",
            "üó£Ô∏è  If I'm hungry, I eat food.\n",
            "ü§ü IF_HUNGRY EAT\n",
            "   condition=IF_HUNGRY\n",
            "\n",
            "üó£Ô∏è  On the weekend, I sleep in.\n",
            "ü§ü IF_WEEKEND HOME STAY\n",
            "   condition=IF_WEEKEND\n",
            "\n",
            "üó£Ô∏è  After work, I go home.\n",
            "ü§ü IF_FINISH_WORK HOME GO\n",
            "   condition=IF_FINISH_WORK\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/onnxruntime/capi/onnxruntime_inference_collection.py:123: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üó£Ô∏è  After school, I play games.\n",
            "ü§ü IF_FINISH_SCHOOL HOME GO\n",
            "   condition=IF_FINISH_SCHOOL\n",
            "\n",
            "üó£Ô∏è  If I'm free, I meet friends.\n",
            "ü§ü IF_FREE HOME STAY\n",
            "   condition=IF_FREE\n",
            "\n",
            "üó£Ô∏è  If I'm busy, I skip lunch.\n",
            "ü§ü IF_BUSY OFFICE WORK\n",
            "   condition=IF_BUSY\n",
            "\n",
            "üó£Ô∏è  If I have money, I go shopping.\n",
            "ü§ü IF_HAVE_MONEY STORE BUY\n",
            "   condition=IF_HAVE_MONEY\n",
            "\n",
            "üó£Ô∏è  When I'm broke, I stay home.\n",
            "ü§ü IF_NO_MONEY HOME STAY\n",
            "   condition=IF_NO_MONEY\n",
            "\n",
            "üó£Ô∏è  N·∫øu m∆∞a th√¨ t√¥i ·ªü nh√†.\n",
            "ü§ü IF_RAIN HOME STAY\n",
            "   condition=IF_RAIN\n",
            "\n",
            "üó£Ô∏è  N·∫øu ƒë√≥i th√¨ t√¥i ƒÉn.\n",
            "ü§ü IF_HUNGRY EAT\n",
            "   condition=IF_HUNGRY\n",
            "\n",
            "üó£Ô∏è  ÊòéÊó•„ÄÅÂ≠¶Ê†°„Å´Ë°å„Åç„Åæ„Åô„ÄÇ\n",
            "ü§ü TOMORROW STAY\n",
            "   condition=NONE\n",
            "\n",
            "üó£Ô∏è  Áñ≤„Çå„Åü„Çâ„ÄÅÂÆ∂„Åß‰ºë„Åø„Åæ„Åô„ÄÇ\n",
            "ü§ü IF_SICK HOME STAY REST\n",
            "   condition=IF_SICK\n",
            "\n",
            "üó£Ô∏è  Je travaille √† l'h√¥pital.\n",
            "ü§ü HOSPITAL WORK\n",
            "   condition=NONE\n",
            "\n",
            "üó£Ô∏è  Si je suis fatigu√©, je me repose.\n",
            "ü§ü IF_TIRED HOME STAY REST\n",
            "   condition=IF_TIRED\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# TEST ONNX INFERENCE\n",
        "# ============================================================\n",
        "\n",
        "import onnxruntime as ort\n",
        "import time\n",
        "\n",
        "print(\"üß™ Testing ONNX inference...\")\n",
        "\n",
        "# Load tokenizer\n",
        "from tokenizers import Tokenizer\n",
        "tokenizer = Tokenizer.from_file(f\"{OUTPUT_DIR}/tokenizer.json\")\n",
        "\n",
        "# Load ONNX model\n",
        "session = ort.InferenceSession(ONNX_PATH, providers=['CUDAExecutionProvider', 'CPUExecutionProvider'])\n",
        "print(f\"   Provider: {session.get_providers()[0]}\")\n",
        "\n",
        "# GLOSS order\n",
        "GLOSS_ORDER = [\"modifier\", \"time\", \"condition\", \"agent\", \"location\", \"object\", \"event\", \"purpose\"]\n",
        "\n",
        "def predict(text):\n",
        "    enc = tokenizer.encode(text)\n",
        "    input_ids = np.array([enc.ids], dtype=np.int64)\n",
        "    attention_mask = np.array([enc.attention_mask], dtype=np.int64)\n",
        "\n",
        "    outputs = session.run(None, {\n",
        "        \"input_ids\": input_ids,\n",
        "        \"attention_mask\": attention_mask\n",
        "    })\n",
        "\n",
        "    csf = {}\n",
        "    for i, slot in enumerate(SLOT_NAMES):\n",
        "        pred_id = np.argmax(outputs[i])\n",
        "        csf[slot] = ID_TO_LABEL[slot][pred_id]\n",
        "    return csf\n",
        "\n",
        "def to_gloss(csf):\n",
        "    tokens = []\n",
        "    for slot in GLOSS_ORDER:\n",
        "        val = csf.get(slot)\n",
        "        if val and val != \"NONE\" and not (slot == \"agent\" and val == \"ME\"):\n",
        "            tokens.append(val)\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "# Test examples\n",
        "test_examples = [\n",
        "    # Basic\n",
        "    \"I go to school tomorrow.\",\n",
        "    \"She stays at home.\",\n",
        "\n",
        "    # Weather conditions\n",
        "    \"If it rains, I stay home.\",\n",
        "    \"If it's sunny, I go to the park.\",\n",
        "\n",
        "    # Mood conditions\n",
        "    \"If I'm bored, I watch Netflix.\",\n",
        "    \"When I'm tired, I take a nap.\",\n",
        "    \"If I'm hungry, I eat food.\",\n",
        "\n",
        "    # Time conditions\n",
        "    \"On the weekend, I sleep in.\",\n",
        "    \"After work, I go home.\",\n",
        "    \"After school, I play games.\",\n",
        "\n",
        "    # Schedule conditions\n",
        "    \"If I'm free, I meet friends.\",\n",
        "    \"If I'm busy, I skip lunch.\",\n",
        "\n",
        "    # Financial conditions\n",
        "    \"If I have money, I go shopping.\",\n",
        "    \"When I'm broke, I stay home.\",\n",
        "\n",
        "    # Multilingual\n",
        "    \"N·∫øu m∆∞a th√¨ t√¥i ·ªü nh√†.\",\n",
        "    \"N·∫øu ƒë√≥i th√¨ t√¥i ƒÉn.\",\n",
        "    \"ÊòéÊó•„ÄÅÂ≠¶Ê†°„Å´Ë°å„Åç„Åæ„Åô„ÄÇ\",\n",
        "    \"Áñ≤„Çå„Åü„Çâ„ÄÅÂÆ∂„Åß‰ºë„Åø„Åæ„Åô„ÄÇ\",\n",
        "    \"Je travaille √† l'h√¥pital.\",\n",
        "    \"Si je suis fatigu√©, je me repose.\",\n",
        "]\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"üìù INFERENCE EXAMPLES\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "for text in test_examples:\n",
        "    csf = predict(text)\n",
        "    gloss = to_gloss(csf)\n",
        "    print(f\"\\nüó£Ô∏è  {text}\")\n",
        "    print(f\"ü§ü {gloss}\")\n",
        "    print(f\"   condition={csf['condition']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gY9gZIDg414N",
        "outputId": "167dc24c-531f-4ae8-d6a7-75104c7459ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "‚è±Ô∏è  BENCHMARK\n",
            "============================================================\n",
            "\n",
            "üìä Results (100 runs):\n",
            "   Mean:       3.02 ms\n",
            "   Std:        0.08 ms\n",
            "   Min:        2.94 ms\n",
            "   Max:        3.53 ms\n",
            "   P50:        3.00 ms\n",
            "   P95:        3.11 ms\n",
            "   Throughput: 331 inferences/sec\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# BENCHMARK\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"‚è±Ô∏è  BENCHMARK\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Prepare input\n",
        "test_text = \"If I'm hungry, I eat food.\"\n",
        "enc = tokenizer.encode(test_text)\n",
        "input_feed = {\n",
        "    \"input_ids\": np.array([enc.ids], dtype=np.int64),\n",
        "    \"attention_mask\": np.array([enc.attention_mask], dtype=np.int64)\n",
        "}\n",
        "\n",
        "# Warmup\n",
        "for _ in range(20):\n",
        "    _ = session.run(None, input_feed)\n",
        "\n",
        "# Benchmark\n",
        "n_runs = 100\n",
        "times = []\n",
        "for _ in range(n_runs):\n",
        "    start = time.perf_counter()\n",
        "    _ = session.run(None, input_feed)\n",
        "    times.append((time.perf_counter() - start) * 1000)\n",
        "\n",
        "print(f\"\\nüìä Results ({n_runs} runs):\")\n",
        "print(f\"   Mean:       {np.mean(times):.2f} ms\")\n",
        "print(f\"   Std:        {np.std(times):.2f} ms\")\n",
        "print(f\"   Min:        {np.min(times):.2f} ms\")\n",
        "print(f\"   Max:        {np.max(times):.2f} ms\")\n",
        "print(f\"   P50:        {np.percentile(times, 50):.2f} ms\")\n",
        "print(f\"   P95:        {np.percentile(times, 95):.2f} ms\")\n",
        "print(f\"   Throughput: {1000/np.mean(times):.0f} inferences/sec\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2939sJH414N"
      },
      "source": [
        "## üìã Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XT6vKrvX414N",
        "outputId": "9af46096-6135-4580-c989-4f4d82f5230d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "üìã CSF BROWSER v4 - TRAINING SUMMARY\n",
            "============================================================\n",
            "\n",
            "üìÅ Output files:\n",
            "   model.onnx          : 433.7 KB\n",
            "   tokenizer.json      : 321.4 KB\n",
            "   config.json         : 0.5 KB\n",
            "   labels.json         : 1.2 KB\n",
            "   ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "   TOTAL               : 0.74 MB\n",
            "\n",
            "üìä Model Stats:\n",
            "   Training samples: 16,996\n",
            "   Validation samples: 1,889\n",
            "   Best accuracy: 99.03%\n",
            "   Condition types: 35\n",
            "   Total output classes: 73\n",
            "\n",
            "üéØ Condition Categories:\n",
            "   Weather     : 5 conditions\n",
            "   Time        : 5 conditions\n",
            "   Health      : 5 conditions\n",
            "   Schedule    : 4 conditions\n",
            "   Mood        : 5 conditions\n",
            "   Social      : 3 conditions\n",
            "   Activity    : 5 conditions\n",
            "   Financial   : 2 conditions\n",
            "\n",
            "‚úÖ Training complete!\n",
            "   Output directory: /content/drive/MyDrive/csf_browser_v4\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# FINAL SUMMARY\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"üìã CSF BROWSER v4 - TRAINING SUMMARY\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# File sizes\n",
        "files = {\n",
        "    \"model.onnx\": f\"{OUTPUT_DIR}/model.onnx\",\n",
        "    \"tokenizer.json\": f\"{OUTPUT_DIR}/tokenizer.json\",\n",
        "    \"config.json\": f\"{OUTPUT_DIR}/config.json\",\n",
        "    \"labels.json\": f\"{OUTPUT_DIR}/labels.json\",\n",
        "}\n",
        "\n",
        "total_size = 0\n",
        "print(f\"\\nüìÅ Output files:\")\n",
        "for name, path in files.items():\n",
        "    if os.path.exists(path):\n",
        "        size = os.path.getsize(path)\n",
        "        total_size += size\n",
        "        if size > 1024 * 1024:\n",
        "            print(f\"   {name:20s}: {size/1024/1024:.2f} MB\")\n",
        "        else:\n",
        "            print(f\"   {name:20s}: {size/1024:.1f} KB\")\n",
        "\n",
        "print(f\"   {'‚îÄ' * 30}\")\n",
        "print(f\"   {'TOTAL':20s}: {total_size/1024/1024:.2f} MB\")\n",
        "\n",
        "print(f\"\\nüìä Model Stats:\")\n",
        "print(f\"   Training samples: {len(train_data):,}\")\n",
        "print(f\"   Validation samples: {len(val_data):,}\")\n",
        "print(f\"   Best accuracy: {best_val_acc:.2f}%\")\n",
        "print(f\"   Condition types: {len(LABELS['condition'])}\")\n",
        "print(f\"   Total output classes: {sum(NUM_CLASSES.values())}\")\n",
        "\n",
        "print(f\"\\nüéØ Condition Categories:\")\n",
        "categories = {\n",
        "    \"Weather\": [\"IF_RAIN\", \"IF_SUNNY\", \"IF_COLD\", \"IF_HOT\", \"IF_WINDY\"],\n",
        "    \"Time\": [\"IF_LATE\", \"IF_EARLY\", \"IF_WEEKEND\", \"IF_NIGHT\", \"IF_MORNING\"],\n",
        "    \"Health\": [\"IF_SICK\", \"IF_TIRED\", \"IF_HUNGRY\", \"IF_THIRSTY\", \"IF_FULL\"],\n",
        "    \"Schedule\": [\"IF_BUSY\", \"IF_FREE\", \"IF_HOLIDAY\", \"IF_WORKING\"],\n",
        "    \"Mood\": [\"IF_BORED\", \"IF_HAPPY\", \"IF_SAD\", \"IF_STRESSED\", \"IF_ANGRY\"],\n",
        "    \"Social\": [\"IF_ALONE\", \"IF_WITH_FRIENDS\", \"IF_WITH_FAMILY\"],\n",
        "    \"Activity\": [\"IF_FINISH_WORK\", \"IF_FINISH_SCHOOL\", \"IF_FINISH_EATING\", \"IF_WATCH_MOVIE\", \"IF_LISTEN_MUSIC\"],\n",
        "    \"Financial\": [\"IF_HAVE_MONEY\", \"IF_NO_MONEY\"],\n",
        "}\n",
        "for cat, conds in categories.items():\n",
        "    print(f\"   {cat:12s}: {len(conds)} conditions\")\n",
        "\n",
        "print(f\"\\n‚úÖ Training complete!\")\n",
        "print(f\"   Output directory: {OUTPUT_DIR}\")\n",
        "print(\"=\" * 60)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
